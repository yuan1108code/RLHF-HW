# 🚀 RLHF 作業專案 - Reinforcement Learning with Human Feedback (RLHF)

歡迎來到 **RLHF 作業專案**！這個 GitHub Repository 主要用來儲存 **強化學習與人類反饋 (Reinforcement Learning with Human Feedback, RLHF)** 相關的作業與實驗結果 🎯。



## 📁 目錄結構
本倉庫包含 RLHF 相關的實作作業，以下是主要內容：

### **HW1&HW2 - Gridworld** 🏗️
#### **HW1-1: 網格地圖開發 🗺️**
- **目標**：開發一個 `n x n` 網格地圖，允許使用者設定 **起點** 🟩、**目標點** 🟥，並設置 **n-2 個障礙物** ⬛。
- **互動方式**：
  - 滑鼠點擊設置環境。
  - 透過 Flask 網頁應用程式實現。

#### **HW1-2: 策略顯示與價值評估 📊**
- **目標**：顯示每個格子的 **隨機策略**（⬆️⬇️⬅️➡️），並透過 **策略評估 (Policy Evaluation)** 計算 `V(s)`。
- **主要功能**：
  - 計算並顯示 **價值函數 V(s)**，幫助理解各個狀態的價值。

#### **HW2: 使用價值迭代推導最佳政策 🔄**
- **目標**：實作 **價值迭代 (Value Iteration)**，計算並顯示 **最佳策略**。
- **主要功能**：
  - 透過價值迭代更新策略，讓行動方向從隨機變為最優決策 🏆。
  - 顯示最終的 **價值函數 V(s)**，展現 AI 學習後的決策能力 📈。

